---
title: "Week_7 Classification 2"
---

## Summary

This week we further study the remote sensing classification, including land cover classification methods, sub-pixel analysis, accuracy assessment, and cross-validation techniques.

### Sub-pixel Classification

**Sub-pixel classification**, also known as **Spectral Mixture Analysis (SMA)** or Linear spectral unmixing, aims to identify the proportion of different land cover types within a single pixel, offering a more detailed understanding of pixel composition beyond the dominant land cover class. This technique relies on the premise that the observed reflectance of a pixel is a linear combination of the reflectances of pure land cover classes (endmembers), weighted by their fractional coverage within the pixel.

### Object-Based Image Analysis
**Object-Based Image Analysis(OBIA)** aims to segment image into a series of objects or regions for analysis, taking into account the shape, texture and context information of the object. OBIA is suitable for high-resolution images and can better handle complex structures and boundaries in images.

### Accuracy Assessment 

Accuracy assessment is crucial for evaluating the performance of land cover classification models. It involves comparing the classification output against a reference dataset (ground truth) to compute various accuracy metrics:

* Producer's Accuracy (Recall): Indicates how well the classification matches the reference data from the perspective of the data producer.
* User's Accuracy (Precision): Reflects the reliability of the classification from the user's point of view, showing how often the classified land cover type matches the reference data.
* Overall Accuracy: The fraction of correctly classified pixels across all land cover types.
* Kappa Coefficient: Measures agreement between the classification and the reference data, accounting for chance agreement.

### Cross-validation 

Cross-validation is a robust method for assessing the generalizability of a classification model by partitioning the data into complementary subsets, training the model on one subset, and validating it on the other. **Spatial cross-validation** addresses the spatial autocorrelation between training and test sets by ensuring that spatially close observations are included in the same fold. This method is particularly relevant for geographic data, where spatial autocorrelation can artificially inflate model performance metrics.

This week emphasizes the importance of considering spatial autocorrelation in model training and validation. Spatially close data points are likely to have similar values, which can influence the model's accuracy assessment if not properly addressed through techniques like spatial cross-validation.

## Application
### OBIA
Here I read an essay introduce the application of the trajectory error matrix for assessing the temporal transferability of OBIA for slum detection.
Considering the dynamic nature of urban development and the complexity of defining and identifying slum areas, the paper team chose to apply OBIA to test the slums in different time frames. In three months, the government completed the construction of a road for river inspection.
```{r echo=FALSE, out.width = "100%", fig.align='center', cache=FALSE, fig.cap="(Source: Jati.P, 2018)"}
    knitr::include_graphics('https://github.com/jianghan0v0/Learning-diary-han-jiang/raw/main/images/wk7-5.jpg')
```
```{r echo=FALSE, out.width = "100%", fig.align='center', cache=FALSE, fig.cap="(Source: Jati.P, 2018)"}
    knitr::include_graphics('https://github.com/jianghan0v0/Learning-diary-han-jiang/raw/main/images/wk7-4.jpg')
```

Notably, this essay make TEM as a tool for assessing the temporal transferability of OBIA, which is innovative and insightful!
```{r echo=FALSE, out.width = "100%", fig.align='center', cache=FALSE, fig.cap="(Source: Jati.P, 2018)"}
    knitr::include_graphics('https://github.com/jianghan0v0/Learning-diary-han-jiang/raw/main/images/wk7-7.jpg')
```
However, the study also reveals that achieving high levels of accuracy and transferability requires careful consideration of local conditions, comprehensive reference data, and potentially, the integration of additional data sources or analytical layers to enhance OBIA's sensitivity to nuanced urban changes. All in all, these essay is a nice caase study for me to understand how OBIA is applied in a project. [(OBIA)](https://doi.org/10.1080/22797254.2018.1496798)


### Sub-Pixel vs. Super-pixel-based
During background reseach, I found super-sub-pixel and i'm really interested in these two's differences. So i read the essay that  using the Gaofen-2 high spatial resolution imagery to compare sub-pixel and super-pixel strategies for mapping urban and rural greenspaces. 

Weida Yin and Jian Yang[(2016)](https://www.tandfonline.com/doi/figure/10.1080/01431161.2017.1354266?scroll=top&needAccess=true) explores the comparative effectiveness of sub-pixel and super-pixel strategies in mapping urban greenspaces using high-resolution satellite imagery. 

For this figure, we can see from upper to lower the pictures represent multispectral imagery, sub-pixel result, super-pixel result. We can see that in the second row, the sub-pixel detects a mix of different features in one pixel and tries to quantify their respective proportions. The third line, as a superpixel result, shows that the image is split into larger blocks where the pixels within these blocks are similar in some properties and can therefore be processed as a whole.
```{r echo=FALSE, out.width = "100%", fig.align='center', cache=FALSE, fig.cap="(Source: Weida.Y, 2016)"}
    knitr::include_graphics('https://github.com/jianghan0v0/Learning-diary-han-jiang/raw/main/images/wk7-8.jpg')
```

From this study, we can summarize their differences.
First, in terms of resolution and detail, subpixel analysis can provide details beyond traditional pixel grids, while superpixels focus more on the similarity between pixels and the integrity of the region.
Second, in terms of application purpose, subpixel method is more suitable for accurate detection and measurement, such as edge detection or fine feature classification. Superpixels are suitable for image segmentation and structured representation, which helps to improve the efficiency of subsequent analysis.

[Fakhereh.A, 2015](https://www.tandfonline.com/doi/epdf/10.1080/19479832.2015.1055834?needAccess=true)
[Weida.Y, 2017](https://www.tandfonline.com/doi/full/10.1080/01431161.2017.1354266)


## Further study-Segmentation

{{< video https://www.youtube.com/watch?v=2R0aTaMtYTY >}}

In a further exploration of image segmentation techniques, I delved into two very interesting techniques by reading the literature: Simple Linear Iterative Clustering (SLIC) and its improved version, Simple Non-Iterative Clustering[(SNIC)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Achanta_Superpixels_and_Polygons_CVPR_2017_paper.pdf).

SLIC was the first superpixel segmentation algorithm I came across. It clusters pixels by performing local K-means optimization within a five-dimensional space (color and spatial coordinates). The charm of SLIC is that it is simple and efficient, requiring only two input parameters: the number of superpixels required and the compactness factor that controls the compactness of the superpixels. However, the difficulty of learning SLIC lies in understanding its iterative process and how to select the appropriate parameters to achieve the best segmentation effect. In addition, SLIC requires multiple iterations to converge during processing, which means that time efficiency can be a challenge when working with very large image sets.

However, SNIC offers a faster and less memory-intensive segmentation method than SLIC. By updating the center of mass directly in a single iteration and explicitly enforcing connectivity from the start, SNIC effectively addresses some of the limitations that exist with SLIC. I think the main difficulty in learning SNIC is to understand how it uses the priority queue to select the next pixel to be added to the cluster, and the process of updating the center of mass online.

## Reflection
OBIA is a powerful tool that can adapt to complex environmental data, however, it relies heavily on the high accuracy of remote sensing data, which makes it very sensitive to accuracy, which is actually a disadvantage for practical project operations. So, what can be done to make up for this disadvantage? I made the following summary: 
* First method I recommand is machine deep learning, use advanced machine learning and deep learning algorithms can extract useful information from lower resolution data, improving the accuracy of classification and recognition. 
* Secondly, combining data from different sources and resolutions, such as combining high-resolution optical images with radar data, can improve the accuracy and robustness of the analysis. It's inevitable to meet many difficulties in the application of OBIA, 

And for pixel-based analysis, sub-pixel and super-pixel, it's interesting to summarize their peculiarity and application areas together. Subpixel technology is often used in scenes requiring high precision analysis, such as fine classification of remote sensing images. Superpixel technology is suitable for applications where analysis can be performed efficiently on a larger scale, such as object recognition or scene understanding. These all deserve to further study.
## Reference
Jati Pratomo, Monika Kuffer, Divyani Kohli & Javier Martinez (2018) Application of the trajectory error matrix for assessing the temporal transferability of OBIA for slum detection, European Journal of Remote Sensing, 51:1, 838-849, DOI: 10.1080/22797254.2018.1496798

Duro, D. C., Franklin, S. E., & Dubé, M. G. (2012). Multi-scale Object-Based Image Analysis and Feature Selection of Multi-sensor Earth Observation Imagery Using Random Forests. International Journal of Remote Sensing, 33(14), 4502-4526.

Wang, F., Wang, M., & Liu, Z. (2015). Wetland Change Detection Using Object-Based Image Analysis and Open-Source Remote Sensing Data in the Niger Delta, Nigeria. Wetlands, 35(1), 11-23.

Hansen, M. C., Potapov, P. V., Moore, R., Hancher, M., Turubanova, S. A., Tyukavina, A., Thau, D., Stehman, S. V., Goetz, S. J., Loveland, T. R., Kommareddy, A., Egorov, A., Chini, L., Justice, C. O., & Townshend, J. R. G. (2013). High-Resolution Global Maps of 21st-Century Forest Cover Change. Science, 342(6160), 850-853.

Friedl, M. A., Sulla-Menashe, D., Tan, B., Schneider, A., Ramankutty, N., Sibley, A., & Huang, X. (2010). MODIS Collection 5 Global Land Cover: Algorithm Refinements and Characterization of New Datasets. Remote Sensing of Environment, 114(1), 168-182.

Weida Yin & Jian Yang (2017) Sub-pixel vs. super-pixel-based greenspace mapping along the urban–rural gradient using high spatial resolution Gaofen-2 satellite imagery: a case study of Haidian District, Beijing, China, International Journal of Remote Sensing, 38:22, 6386-6406, DOI: 10.1080/01431161.2017.1354266

S Gokool, Es Riddell, C Jarmain, Kt Chetty, G Feig & H Thenga. (2020) Evaluating the accuracy of satellite-derived evapotranspiration estimates acquired during conditions of water stress. International Journal of Remote Sensing 41:2, pages 704-724. 
